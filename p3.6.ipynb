{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22602\n"
     ]
    }
   ],
   "source": [
    "wwMatrix = []\n",
    "with open(\"wwMatrix.csv\", \"r\") as f:\n",
    "\treader = csv.reader(f)\n",
    "\tfor row in reader:\n",
    "\t\twwMatrix.append(row)\n",
    "print(len(wwMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playName = open(\"play_names.txt\", \"r\")\n",
    "plays_comedy = [\"The Tempest\", \"Two Gentlemen of Verona\", \"Merry Wives of Windsor\", \"Measure for measure\", \"A Comedy of Errors\", \"Much Ado about nothing\", \"Loves Labours Lost\", \"A Midsummer nights dream\", \"Merchant of Venice\", \"As you like it\", \"Taming of the Shrew\", \"Alls well that ends well\", \"Twelfth Night\", \"A Winters Tale\", \"Pericles\"]\n",
    "plays_history = [\"King John\", \"Richard II\", \"Richard III\", \"Henry IV\", \"Henry VI Part 2\", \"Henry VIII\", \"Henry VI Part 1\", \"Henry V\", \"Henry VI Part 3\"]\n",
    "plays_tragedy = [\"Troilus and Cressida\", \"Coriolanus\", \"Titus Andronicus\", \"Romeo and Juliet\", \"Timon of Athens\", \"Julius Caesar\", \"macbeth\", \"Hamlet\", \"King Lear\", \"Othello\", \"Antony and Cleopatra\", \"Cymbeline\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_doc = {}\n",
    "doc = pd.read_csv(\"will_play_text.csv\", sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for play in plays_comedy:\n",
    "\tlines = []\n",
    "\tfor row in range(len(doc)):\n",
    "\t\tif doc[1][row] == play:\n",
    "\t\t\tlines.append(doc[5][row])\n",
    "\tplay_doc[play] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_token = {}\n",
    "for play in plays_comedy:\n",
    "\tplay_token[play] = []\n",
    "\tfor sentence in play_doc[play]:\n",
    "\t\tplay_token[play] = play_token[play] + nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.txt\", \"r\") as f:\n",
    "\tvocab = f.readlines()\n",
    "for i in range(len(vocab)):\n",
    "\tvocab[i] = vocab[i].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_comedy_vec = {}\n",
    "for play in plays_comedy:\n",
    "\tvec = np.zeros(22602)\n",
    "\t# print(vec)\n",
    "\tcount = 0\n",
    "\tfor w in play_token[play]:\n",
    "\t\tif w in vocab:\n",
    "\t\t\tcount += 1\n",
    "\t\t\twordvec = np.array(wwMatrix[vocab.index(w)]).astype(float)\n",
    "\t\t\tvec = vec + wordvec\n",
    "\t\t\t# print(vec)\n",
    "\tplay_comedy_vec[play] = vec/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996479494041783\n"
     ]
    }
   ],
   "source": [
    "play_comedy_matrix = []\n",
    "for play in plays_comedy:\n",
    "    play_comedy_matrix.append(play_comedy_vec[play])\n",
    "comedy_sim = cosine_similarity(play_comedy_matrix, play_comedy_matrix)\n",
    "print(np.ndarray.mean(comedy_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for play in plays_history:\n",
    "\tlines = []\n",
    "\tfor row in range(len(doc)):\n",
    "\t\tif doc[1][row] == play:\n",
    "\t\t\tlines.append(doc[5][row])\n",
    "\tplay_doc[play] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for play in plays_history:\n",
    "\tplay_token[play] = []\n",
    "\tfor sentence in play_doc[play]:\n",
    "\t\tplay_token[play] = play_token[play] + nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_history_vec = {}\n",
    "for play in plays_history:\n",
    "\tvec = np.zeros(22602)\n",
    "\t# print(vec)\n",
    "\tcount = 0\n",
    "\tfor w in play_token[play]:\n",
    "\t\tif w in vocab:\n",
    "\t\t\tcount += 1\n",
    "\t\t\twordvec = np.array(wwMatrix[vocab.index(w)]).astype(float)\n",
    "\t\t\tvec = vec + wordvec\n",
    "\t\t\t# print(vec)\n",
    "\tplay_history_vec[play] = vec/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998483889464223\n"
     ]
    }
   ],
   "source": [
    "play_history_matrix = []\n",
    "for play in plays_history:\n",
    "    play_history_matrix.append(play_history_vec[play])\n",
    "history_sim = cosine_similarity(play_history_matrix, play_history_matrix)\n",
    "print(np.ndarray.mean(history_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for play in plays_tragedy:\n",
    "\tlines = []\n",
    "\tfor row in range(len(doc)):\n",
    "\t\tif doc[1][row] == play:\n",
    "\t\t\tlines.append(doc[5][row])\n",
    "\tplay_doc[play] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for play in plays_tragedy:\n",
    "\tplay_token[play] = []\n",
    "\tfor sentence in play_doc[play]:\n",
    "\t\tplay_token[play] = play_token[play] + nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_tragedy_matrix = []\n",
    "for play in plays_tragedy:\n",
    "\tvec = np.zeros(22602)\n",
    "\t# print(vec)\n",
    "\tcount = 0\n",
    "\tfor w in play_token[play]:\n",
    "\t\tif w in vocab:\n",
    "\t\t\tcount += 1\n",
    "\t\t\twordvec = np.array(wwMatrix[vocab.index(w)]).astype(float)\n",
    "\t\t\tvec = vec + wordvec\n",
    "\t\t\t# print(vec)\n",
    "\tplay_tragedy_matrix.append(vec/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997173678480359\n"
     ]
    }
   ],
   "source": [
    "tragedy_sim = cosine_similarity(play_tragedy_matrix, play_tragedy_matrix)\n",
    "print(np.ndarray.mean(tragedy_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
